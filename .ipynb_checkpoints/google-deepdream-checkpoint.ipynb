{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "import scipy\n",
    "from keras.applications import inception_v3\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_image_path = 'a.jpeg'\n",
    "result_prefix = 'results/dream'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the names of the layers\n",
    "# for which we try to maximize activation,\n",
    "# as well as their weight in the final loss\n",
    "# we try to maximize.\n",
    "# You can tweak these setting to obtain new visual effects.\n",
    "settings = {\n",
    "    'features': {\n",
    "        'mixed2': 0.2,\n",
    "        'mixed3': 0.5,\n",
    "        'mixed4': 2.,\n",
    "        'mixed5': 1.5,\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'inception5h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-1805918220d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minception5h\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'inception5h'"
     ]
    }
   ],
   "source": [
    "import inception5h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Util function to open, resize and format pictures\n",
    "    # into appropriate tensors.\n",
    "    img = load_img(image_path)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # Util function to convert a tensor into a valid image.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = inception_v3.InceptionV3(weights=None, include_top=False)\n",
    "# model = load_model('model.h5')\n",
    "dream = model.input\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss.\n",
    "loss = K.variable(0.)\n",
    "for layer_name in settings['features']:\n",
    "    # Add the L2 norm of the features of a layer to the loss.\n",
    "    if layer_name not in layer_dict:\n",
    "        raise ValueError('Layer ' + layer_name + ' not found in model.')\n",
    "    coeff = settings['features'][layer_name]\n",
    "    x = layer_dict[layer_name].output\n",
    "    # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "    scaling = K.prod(K.cast(K.shape(x), 'float32'))\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = loss + coeff * K.sum(K.square(x[:, :, 2: -2, 2: -2])) / scaling\n",
    "    else:\n",
    "        loss = loss + coeff * K.sum(K.square(x[:, 2: -2, 2: -2, :])) / scaling\n",
    "\n",
    "# Compute the gradients of the dream wrt the loss.\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "# Normalize gradients.\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), K.epsilon())\n",
    "\n",
    "# Set up function to retrieve the value\n",
    "# of the loss and gradients given an input image.\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        factors = (1, 1,\n",
    "                   float(size[0]) / img.shape[2],\n",
    "                   float(size[1]) / img.shape[3])\n",
    "    else:\n",
    "        factors = (1,\n",
    "                   float(size[0]) / img.shape[1],\n",
    "                   float(size[1]) / img.shape[2],\n",
    "                   1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('..Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (522, 391)\n",
      "..Loss value at 0 : 0.0001752356\n",
      "..Loss value at 1 : 0.0001779929\n",
      "..Loss value at 2 : 0.00018079\n",
      "..Loss value at 3 : 0.00018363117\n",
      "..Loss value at 4 : 0.00018652147\n",
      "..Loss value at 5 : 0.00018946468\n",
      "..Loss value at 6 : 0.00019246302\n",
      "..Loss value at 7 : 0.00019551959\n",
      "..Loss value at 8 : 0.00019863684\n",
      "..Loss value at 9 : 0.00020181114\n",
      "..Loss value at 10 : 0.00020505273\n",
      "..Loss value at 11 : 0.0002083546\n",
      "..Loss value at 12 : 0.00021171971\n",
      "..Loss value at 13 : 0.00021514663\n",
      "..Loss value at 14 : 0.00021865047\n",
      "..Loss value at 15 : 0.00022222142\n",
      "..Loss value at 16 : 0.00022587164\n",
      "..Loss value at 17 : 0.00022958843\n",
      "..Loss value at 18 : 0.00023339108\n",
      "..Loss value at 19 : 0.00023727141\n",
      "Processing image shape (731, 548)\n",
      "..Loss value at 0 : 0.00017034414\n",
      "..Loss value at 1 : 0.0001716596\n",
      "..Loss value at 2 : 0.00017298643\n",
      "..Loss value at 3 : 0.00017432473\n",
      "..Loss value at 4 : 0.0001756744\n",
      "..Loss value at 5 : 0.00017703445\n",
      "..Loss value at 6 : 0.00017840738\n",
      "..Loss value at 7 : 0.00017979712\n",
      "..Loss value at 8 : 0.00018120075\n",
      "..Loss value at 9 : 0.00018261862\n",
      "..Loss value at 10 : 0.00018405222\n",
      "..Loss value at 11 : 0.00018550002\n",
      "..Loss value at 12 : 0.00018696388\n",
      "..Loss value at 13 : 0.00018844305\n",
      "..Loss value at 14 : 0.00018993663\n",
      "..Loss value at 15 : 0.00019144602\n",
      "..Loss value at 16 : 0.0001929733\n",
      "..Loss value at 17 : 0.00019451776\n",
      "..Loss value at 18 : 0.00019608138\n",
      "..Loss value at 19 : 0.00019765813\n",
      "Processing image shape (1024, 768)\n",
      "..Loss value at 0 : 0.00016331783\n",
      "..Loss value at 1 : 0.00016393333\n",
      "..Loss value at 2 : 0.00016455204\n",
      "..Loss value at 3 : 0.00016517425\n",
      "..Loss value at 4 : 0.00016579985\n",
      "..Loss value at 5 : 0.00016642889\n",
      "..Loss value at 6 : 0.00016706117\n",
      "..Loss value at 7 : 0.00016769645\n",
      "..Loss value at 8 : 0.00016833443\n",
      "..Loss value at 9 : 0.00016897476\n",
      "..Loss value at 10 : 0.00016961858\n",
      "..Loss value at 11 : 0.00017026576\n",
      "..Loss value at 12 : 0.00017091652\n",
      "..Loss value at 13 : 0.00017157203\n",
      "..Loss value at 14 : 0.00017223136\n",
      "..Loss value at 15 : 0.00017289446\n",
      "..Loss value at 16 : 0.00017356125\n",
      "..Loss value at 17 : 0.00017423161\n",
      "..Loss value at 18 : 0.000174906\n",
      "..Loss value at 19 : 0.00017558457\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Process:\n",
    "\n",
    "- Load the original image.\n",
    "- Define a number of processing scales (i.e. image shapes),\n",
    "    from smallest to largest.\n",
    "- Resize the original image to the smallest scale.\n",
    "- For every scale, starting with the smallest (i.e. current one):\n",
    "    - Run gradient ascent\n",
    "    - Upscale image to the next scale\n",
    "    - Reinject the detail that was lost at upscaling time\n",
    "- Stop when we are back to the original size.\n",
    "\n",
    "To obtain the detail lost during upscaling, we simply\n",
    "take the original image, shrink it down, upscale it,\n",
    "and compare the result to the (resized) original image.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Playing with these hyperparameters will also allow you to achieve new effects\n",
    "step = 0.01  # Gradient ascent step size\n",
    "num_octave = 3  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 20  # Number of ascent steps per scale\n",
    "max_loss = 10.\n",
    "\n",
    "img = preprocess_image(base_image_path)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    original_shape = img.shape[2:]\n",
    "else:\n",
    "    original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "\n",
    "save_img(result_prefix + '.png', deprocess_image(np.copy(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
